{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05325d1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x85 in position 986: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 230\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39m# -----Program utama-----------------------------------------------\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 230\u001b[0m     dList, fList \u001b[39m=\u001b[39m stemmingFile(baca_file())\n\u001b[1;32m    232\u001b[0m     \u001b[39m# ---model logistic regression---\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     logRes \u001b[39m=\u001b[39m classiLogRegressi(dList, fList)\n",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m, in \u001b[0;36mbaca_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m readCsv \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(rCsv, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m read \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m readCsv:\n\u001b[1;32m     35\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(row) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     36\u001b[0m         read \u001b[39m=\u001b[39m read \u001b[39m+\u001b[39m [row]\n",
      "File \u001b[0;32m/usr/lib/python3.8/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[1;32m    323\u001b[0m     \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x85 in position 986: invalid start byte"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Feb  6 15:20:04 2019\n",
    "\n",
    "@author: Agus Nursikuwagus\n",
    "classification tweeter\n",
    "\"\"\"\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Reading file from \"Tweet.csv\"\n",
    "\n",
    "\n",
    "def baca_file():\n",
    "\n",
    "    csvF1 = \"datasets/text-processing/tweet.csv\"\n",
    "\n",
    "    # Open file Tweet.csv to manipulate\n",
    "    with open(csvF1, \"r\") as rCsv:\n",
    "        readCsv = csv.reader(rCsv, delimiter=';')\n",
    "        read = []\n",
    "        for row in readCsv:\n",
    "            if len(row) != 0:\n",
    "                read = read + [row]\n",
    "\n",
    "    rCsv.close()\n",
    "    return (read)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Procedure for displaying the result to the console\n",
    "\n",
    "\n",
    "def tampil_csv(f2):\n",
    "    df3 = pd.DataFrame(f2)\n",
    "    print(df3)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Function stemming and return the value of feature and target\n",
    "\n",
    "\n",
    "def stemmingFile(fCsv):\n",
    "\n",
    "    # ---Define a new list for temporary reading---#\n",
    "    rList = []\n",
    "    eList = []\n",
    "\n",
    "    # ---initialization a stopword by Sastrawi---#\n",
    "    facto = StopWordRemoverFactory()\n",
    "    stopwords = facto.create_stop_word_remover()\n",
    "\n",
    "    # ---Looping to read line by line csv file---#\n",
    "    for idx in fCsv:\n",
    "        rList.append(stopwords.remove(idx[0]))\n",
    "\n",
    "        # ---change every word in target to new value---#\n",
    "        if idx[1] == 'Keluhan':\n",
    "            eList.append('1')\n",
    "        elif idx[1] == 'Respon':\n",
    "            eList.append('2')\n",
    "        else:\n",
    "            eList.append('3')\n",
    "        # --- end of IF ---#\n",
    "\n",
    "    # --- end of looping ---#\n",
    "    return (rList, eList)  # parameter return\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# procedure to classify every sample in Tweeter.csv\n",
    "\n",
    "\n",
    "def classiLogRegressi(lRead, rRead):\n",
    "\n",
    "    # ---setting validation 20% fromm data sample---#\n",
    "    validation_size = 0.20\n",
    "    seed = 7\n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(\n",
    "        lRead, rRead, test_size=validation_size, random_state=seed)\n",
    "\n",
    "    # ---TF-IDF vectorizer, collecting value into vector---#\n",
    "    w = TfidfVectorizer()\n",
    "\n",
    "    print('Logistic Regresion')\n",
    "    logistic = LogisticRegression()\n",
    "    logistic = Pipeline([\n",
    "        ('xPipe', w),\n",
    "        ('knn', logistic)])\n",
    "\n",
    "    logistic.fit(X_train, Y_train)\n",
    "    predictions = logistic.predict(X_validation)\n",
    "\n",
    "    print('Akurasi = ', accuracy_score(Y_validation, predictions))\n",
    "    print('Matrix Confussion')\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "\n",
    "    return (logistic)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "def classKNeighborsClassifier(lRead, rRead):\n",
    "\n",
    "    # ---setting validation 20% fromm data sample---#\n",
    "    validation_size = 0.20\n",
    "    seed = 7\n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(\n",
    "        lRead, rRead, test_size=validation_size, random_state=seed)\n",
    "\n",
    "    # ---TF-IDF vectorizer, collecting value into vector---#\n",
    "    w = TfidfVectorizer()\n",
    "#\n",
    "    # ---classification using K-NN---#\n",
    "    print('K-Neighborhood ')\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn = Pipeline([\n",
    "        ('xPipe', w),\n",
    "        ('knn', knn)])\n",
    "\n",
    "    knn.fit(X_train, Y_train)\n",
    "    predictions = knn.predict(X_validation)\n",
    "    print('Akurasi = ', accuracy_score(Y_validation, predictions))\n",
    "    print('Matrix Confussion')\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "\n",
    "    return (knn)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "def classDecisionTree(lRead, rRead):\n",
    "\n",
    "    # ---setting validation 20% fromm data sample---#\n",
    "    validation_size = 0.20\n",
    "    seed = 7\n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(\n",
    "        lRead, rRead, test_size=validation_size, random_state=seed)\n",
    "\n",
    "    # ---TF-IDF vectorizer, collecting value into vector---#\n",
    "    w = TfidfVectorizer()\n",
    "#\n",
    "    # ---classification using K-NN---#\n",
    "    print('Decision Tree')\n",
    "    deTree = DecisionTreeClassifier()\n",
    "    deTree = Pipeline([\n",
    "        ('xPipe', w),\n",
    "        ('knn', deTree)])\n",
    "\n",
    "    deTree.fit(X_train, Y_train)\n",
    "    predictions = deTree.predict(X_validation)\n",
    "    print('Akurasi = ', accuracy_score(Y_validation, predictions))\n",
    "    print('Matrix Confussion')\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "\n",
    "    return (deTree)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "def singleTextLogisticRegression(xText, mknn):\n",
    "\n",
    "    x_test = []\n",
    "    x_test.append(xText)\n",
    "    mpredictions = mknn.predict(x_test)\n",
    "\n",
    "    return (mpredictions)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "\n",
    "def singleTextKNeighbor(xText, cKboar):\n",
    "\n",
    "    x_test = []\n",
    "    x_test.append(xText)\n",
    "    mpredictions = cKboar.predict(x_test)\n",
    "\n",
    "    return (mpredictions)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "def singleTextDecisionTree(xText, dTree):\n",
    "\n",
    "    x_test = []\n",
    "    x_test.append(xText)\n",
    "    mpredictions = dTree.predict(x_test)\n",
    "\n",
    "    return (mpredictions)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "def singleTextNaiveBayes(xText, mBayes):\n",
    "\n",
    "    x_test = []\n",
    "    x_test.append(xText)\n",
    "    mpredictions = mBayes.predict(x_test)\n",
    "\n",
    "    return (mpredictions)\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "def konversiPrediksi(pre):\n",
    "    tulis = ''\n",
    "    if pre == '1':\n",
    "        tulis = 'Keluhan'\n",
    "    elif pre == '2':\n",
    "        tulis = 'Respon'\n",
    "    else:\n",
    "        tulis = 'Not Keluhan/Respon'\n",
    "\n",
    "    return (tulis)\n",
    "\n",
    "\n",
    "# -----Program utama-----------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    dList, fList = stemmingFile(baca_file())\n",
    "\n",
    "    # ---model logistic regression---\n",
    "\n",
    "    logRes = classiLogRegressi(dList, fList)\n",
    "    Neighbor = classKNeighborsClassifier(dList, fList)\n",
    "    DesTree = classDecisionTree(dList, fList)\n",
    "\n",
    "    testing = input('Masukkan text tweet = ')\n",
    "\n",
    "    l = singleTextLogisticRegression(testing, logRes)\n",
    "\n",
    "    k = singleTextKNeighbor(testing, Neighbor)\n",
    "\n",
    "    t = singleTextDecisionTree(testing, DesTree)\n",
    "\n",
    "    print('Prediksi dengan Logistic Regression = ', konversiPrediksi(l))\n",
    "    print('Prediksi dengan K-Nearest Neighirhood =', konversiPrediksi(k))\n",
    "    print('Prediksi dengan Decision Tree = ', konversiPrediksi(t))\n",
    "\n",
    "\n",
    "# ----End of Program-------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
